{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Algorithms\n",
    "\n",
    "In the previous experiment, we have explored some variations of Gradient Descent, particularly, __mini-Batch Gradient Descent (mBGD)__, and __Stochastic Gradient Descent (SGD)__. __Mini-batch Gradient Descent presents as a good alternative for Batch Gradient Descent__, mainly because of its computation efficiency. \n",
    "\n",
    "It turns out that Gradient Descent can further be improved by introducing more dynamic mechanism in adjusting ofweights. Think of the traditional GD (e.g. SGD, mBGD, BGD) as _velocity_ in a world governed by classical Physics. If there's _velocity_, then there should also be _acceleration_, _momentum_, and such!\n",
    "\n",
    "In this notebook, we'll implement __Simple Moment__, __RMSprop__ and __Adam__ optimization algorithms. These 2 have been shown to work well across a wide range of deep learning architectures. \n",
    "\n",
    "* Adam: https://arxiv.org/abs/1412.6980\n",
    "* RMSProp: https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified data/t10k-images-idx3-ubyte.gz\n",
      "Found and verified data/t10k-labels-idx1-ubyte.gz\n",
      "Found and verified data/train-images-idx3-ubyte.gz\n",
      "Found and verified data/train-labels-idx1-ubyte.gz\n",
      "Found and verified data/t10k-images-idx3-ubyte.gz\n",
      "Found and verified data/t10k-labels-idx1-ubyte.gz\n",
      "Found and verified data/train-images-idx3-ubyte.gz\n",
      "Found and verified data/train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist\n",
    "from activation import relu, sigmoid, sigmoid_prime, softmax\n",
    "from helper import one_hot_encoder\n",
    "from initializer import initialize_weight\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import dataloader\n",
    "from losses import cross_entropy_loss\n",
    "\n",
    "# Load Dataset\n",
    "train_x, train_y = mnist.load_dataset(download=True, train=True)\n",
    "test_x, test_y = mnist.load_dataset(download=True, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Moment\n",
    "\n",
    "Here are the equations of weight updates using moment:\n",
    "\n",
    "Keypoints of optimization using moments:\n",
    "\n",
    "1. Moment takes into account the __history of gradient values__. This helps the algorithm in choosing whether to speed up or slow down the gradient descent, and therefore, smoothing the optimization.\n",
    "2. Usual values of beta ranges from __0.8 to 0.999__. The most common value of beta is __0.9__. However, __loss is exploding__, consider using smaller values of beta, around __0.1 to 0.2__.\n",
    "3. One way of checking if your implementation of moment is correct is by setting the beta value to 0. Setting the beta value to 0 is the same as performing normal gradient descent.\n",
    "4. Also, the end values of moment are multiplied by (1-beta_1). This is done to normalize the moments, and to avoid explosion of moment values and gradient updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_moment(train_x, train_y, learning_rate=0.1, num_epochs=50, batch_size=1):\n",
    "    # Flatten input (num_samples, 28, 28) -> (num_samples, 784) \n",
    "    x = train_x.reshape(train_x.shape[0], -1)\n",
    "    num_samples = x.shape[0]\n",
    "    \n",
    "    # Turn labels into their one-hot representations\n",
    "    y = one_hot_encoder(train_y)\n",
    "\n",
    "    # Make a data loader\n",
    "    trainloader = dataloader(x, y, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Initialize weights\n",
    "    w1, b1 = initialize_weight((784, 256), bias=True)\n",
    "    w2, b2 = initialize_weight((256, 10), bias=True)\n",
    "\n",
    "    # Initialize Moments\n",
    "    v_w1, v_b1 = np.zeros(w1.shape), np.zeros(b1.shape)\n",
    "    v_w2, v_b2 = np.zeros(w2.shape), np.zeros(b2.shape)\n",
    "    \n",
    "    # Optimizer Hyperparameters\n",
    "    beta_1 = 0.9\n",
    "    \n",
    "    loss_history = []\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        print(\"Epoch {}/{}\\n===============\".format(epoch, num_epochs))\n",
    "\n",
    "        batch_loss = 0\n",
    "        acc = 0\n",
    "        for inputs, labels in trainloader:\n",
    "            # Number of samples per batch\n",
    "            m = inputs.shape[0]\n",
    "            \n",
    "            # Forward Prop\n",
    "            h1 = np.dot(inputs, w1) + b1\n",
    "            a1 = sigmoid(h1)\n",
    "            h2 = np.dot(a1, w2) + b2\n",
    "            a2 = softmax(h2)\n",
    "            out = a2\n",
    "\n",
    "            # Cross Entropy Loss\n",
    "            batch_loss += cross_entropy_loss(out, labels.argmax(axis=1).reshape(m,1))\n",
    "\n",
    "            # Compute Accuracy\n",
    "            pred = np.argmax(out, axis=1)\n",
    "            pred = pred.reshape(pred.shape[0], 1)\n",
    "            acc += np.sum(pred == labels.argmax(axis=1).reshape(m,1))\n",
    "\n",
    "            # Backward Prop\n",
    "            dh2 = a2 - labels \n",
    "            dw2 = (1/m) * np.dot(a1.T, dh2)\n",
    "            db2 = (1/m) * np.sum(dh2, axis=0, keepdims=True)\n",
    "\n",
    "            dh1 = np.dot(dh2, w2.T) * sigmoid_prime(a1)\n",
    "            dw1 = (1/m) * np.dot(inputs.T, dh1)\n",
    "            db1 = (1/m) * np.sum(dh1, axis=0, keepdims=True)\n",
    "\n",
    "            # 1st Moment\n",
    "            v_w2 += (beta_1 * v_w2 + (1-beta_1) * dw2) * (1-beta_1)\n",
    "            v_b2 += (beta_1 * v_b2 + (1-beta_1) * db2) * (1-beta_1)\n",
    "            v_w1 += (beta_1 * v_w1 + (1-beta_1) * dw1) * (1-beta_1)\n",
    "            v_b1 += (beta_1 * v_b1 + (1-beta_1) * db1) * (1-beta_1)\n",
    "            \n",
    "            # Weight (and bias) update\n",
    "            w1 -= learning_rate * v_w1\n",
    "            b1 -= learning_rate * v_b1\n",
    "            w2 -= learning_rate * v_w2\n",
    "            b2 -= learning_rate * v_b2\n",
    "            \n",
    "        loss_history.append(batch_loss/num_samples)\n",
    "        print(\"Loss: {:.6f}\".format(batch_loss/num_samples))\n",
    "        print(\"Accuracy: {:.2f}%\\n\".format(acc/num_samples*100))\n",
    "\n",
    "    return w1, b1, w2, b2, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "===============\n",
      "Loss: 2.499727\n",
      "Accuracy: 6.87%\n",
      "\n",
      "Epoch 2/20\n",
      "===============\n",
      "Loss: 2.259785\n",
      "Accuracy: 16.03%\n",
      "\n",
      "Epoch 3/20\n",
      "===============\n",
      "Loss: 1.989637\n",
      "Accuracy: 36.00%\n",
      "\n",
      "Epoch 4/20\n",
      "===============\n",
      "Loss: 1.766470\n",
      "Accuracy: 45.96%\n",
      "\n",
      "Epoch 5/20\n",
      "===============\n",
      "Loss: 1.481157\n",
      "Accuracy: 58.89%\n",
      "\n",
      "Epoch 6/20\n",
      "===============\n",
      "Loss: 1.217915\n",
      "Accuracy: 70.73%\n",
      "\n",
      "Epoch 7/20\n",
      "===============\n",
      "Loss: 1.086503\n",
      "Accuracy: 69.41%\n",
      "\n",
      "Epoch 8/20\n",
      "===============\n",
      "Loss: 1.017676\n",
      "Accuracy: 69.73%\n",
      "\n",
      "Epoch 9/20\n",
      "===============\n",
      "Loss: 0.926689\n",
      "Accuracy: 71.26%\n",
      "\n",
      "Epoch 10/20\n",
      "===============\n",
      "Loss: 0.794818\n",
      "Accuracy: 77.99%\n",
      "\n",
      "Epoch 11/20\n",
      "===============\n",
      "Loss: 0.701527\n",
      "Accuracy: 80.54%\n",
      "\n",
      "Epoch 12/20\n",
      "===============\n",
      "Loss: 0.701453\n",
      "Accuracy: 76.54%\n",
      "\n",
      "Epoch 13/20\n",
      "===============\n",
      "Loss: 0.699908\n",
      "Accuracy: 75.22%\n",
      "\n",
      "Epoch 14/20\n",
      "===============\n",
      "Loss: 0.648807\n",
      "Accuracy: 78.19%\n",
      "\n",
      "Epoch 15/20\n",
      "===============\n",
      "Loss: 0.601688\n",
      "Accuracy: 80.55%\n",
      "\n",
      "Epoch 16/20\n",
      "===============\n",
      "Loss: 0.593441\n",
      "Accuracy: 80.47%\n",
      "\n",
      "Epoch 17/20\n",
      "===============\n",
      "Loss: 0.606569\n",
      "Accuracy: 80.04%\n",
      "\n",
      "Epoch 18/20\n",
      "===============\n",
      "Loss: 0.619384\n",
      "Accuracy: 79.85%\n",
      "\n",
      "Epoch 19/20\n",
      "===============\n",
      "Loss: 0.619886\n",
      "Accuracy: 80.44%\n",
      "\n",
      "Epoch 20/20\n",
      "===============\n",
      "Loss: 0.599690\n",
      "Accuracy: 81.44%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w1_m, b1_m, w2_m, b2_m, loss_history_m = train_moment(train_x, train_y, learning_rate=5, num_epochs=20, batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp: 2nd Moment\n",
    "\n",
    "Keypoints:\n",
    "\n",
    "1. Usual values of 2nd moment beta is 0.999. Similar to 1st moment, if the loss value is exploding, consider exploring smaller values of beta, __0.1 to 0.2__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rmsprop(train_x, train_y, learning_rate=0.1, num_epochs=50, batch_size=1):\n",
    "    # Flatten input (num_samples, 28, 28) -> (num_samples, 784) \n",
    "    x = train_x.reshape(train_x.shape[0], -1)\n",
    "    num_samples = x.shape[0]\n",
    "    \n",
    "    # Turn labels into their one-hot representations\n",
    "    y = one_hot_encoder(train_y)\n",
    "\n",
    "    # Make a data loader\n",
    "    trainloader = dataloader(x, y, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Initialize weights\n",
    "    w1, b1 = initialize_weight((784, 256), bias=True)\n",
    "    w2, b2 = initialize_weight((256, 10), bias=True)\n",
    "\n",
    "    # Initialize Moments\n",
    "    s_w1, s_b1 = np.zeros(w1.shape), np.zeros(b1.shape)\n",
    "    s_w2, s_b2 = np.zeros(w2.shape), np.zeros(b2.shape)\n",
    "    \n",
    "    # Optimizer Hyperparameters\n",
    "    beta_2 = 0.1\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    loss_history = []\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        print(\"Epoch {}/{}\\n===============\".format(epoch, num_epochs))\n",
    "\n",
    "        batch_loss = 0\n",
    "        acc = 0\n",
    "        for inputs, labels in trainloader:\n",
    "            # Number of samples per batch\n",
    "            m = inputs.shape[0]\n",
    "            \n",
    "            # Forward Prop\n",
    "            h1 = np.dot(inputs, w1) + b1\n",
    "            a1 = sigmoid(h1)\n",
    "            h2 = np.dot(a1, w2) + b2\n",
    "            a2 = softmax(h2)\n",
    "            out = a2\n",
    "\n",
    "            # Cross Entropy Loss\n",
    "            batch_loss += cross_entropy_loss(out, labels.argmax(axis=1).reshape(m,1))\n",
    "\n",
    "            # Compute Accuracy\n",
    "            pred = np.argmax(out, axis=1)\n",
    "            pred = pred.reshape(pred.shape[0], 1)\n",
    "            acc += np.sum(pred == labels.argmax(axis=1).reshape(m,1))\n",
    "\n",
    "            # Backward Prop\n",
    "            dh2 = a2 - labels \n",
    "            dw2 = (1/m) * np.dot(a1.T, dh2)\n",
    "            db2 = (1/m) * np.sum(dh2, axis=0, keepdims=True)\n",
    "\n",
    "            dh1 = np.dot(dh2, w2.T) * sigmoid_prime(a1)\n",
    "            dw1 = (1/m) * np.dot(inputs.T, dh1)\n",
    "            db1 = (1/m) * np.sum(dh1, axis=0, keepdims=True)\n",
    "            \n",
    "            # 2nd Moment\n",
    "            s_w2 += beta_2 * s_w2 + (1-beta_2) * dw2 * dw2\n",
    "            s_b2 += beta_2 * s_b2 + (1-beta_2) * db2 * db2\n",
    "            s_w1 += beta_2 * s_w1 + (1-beta_2) * dw1 * dw1\n",
    "            s_b1 += beta_2 * s_b1 + (1-beta_2) * db1 * db1\n",
    "            \n",
    "            # Weight (and bias) update\n",
    "            w1 -= learning_rate * dw1 / (np.sqrt(s_w1) + epsilon)\n",
    "            b1 -= learning_rate * db1 / (np.sqrt(s_b1) + epsilon)\n",
    "            w2 -= learning_rate * dw2 / (np.sqrt(s_w2) + epsilon)\n",
    "            b2 -= learning_rate * db2 / (np.sqrt(s_b2) + epsilon)\n",
    "            \n",
    "        loss_history.append(batch_loss/num_samples)\n",
    "        print(\"Loss: {:.6f}\".format(batch_loss/num_samples))\n",
    "        print(\"Accuracy: {:.2f}%\\n\".format(acc/num_samples*100))\n",
    "\n",
    "    return w1, b1, w2, b2, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "===============\n",
      "Loss: 2.451064\n",
      "Accuracy: 9.40%\n",
      "\n",
      "Epoch 2/20\n",
      "===============\n",
      "Loss: 3.751505\n",
      "Accuracy: 26.60%\n",
      "\n",
      "Epoch 3/20\n",
      "===============\n",
      "Loss: 2.553249\n",
      "Accuracy: 35.91%\n",
      "\n",
      "Epoch 4/20\n",
      "===============\n",
      "Loss: 1.992432\n",
      "Accuracy: 26.72%\n",
      "\n",
      "Epoch 5/20\n",
      "===============\n",
      "Loss: 1.360959\n",
      "Accuracy: 63.41%\n",
      "\n",
      "Epoch 6/20\n",
      "===============\n",
      "Loss: 1.003484\n",
      "Accuracy: 73.29%\n",
      "\n",
      "Epoch 7/20\n",
      "===============\n",
      "Loss: 0.841040\n",
      "Accuracy: 80.51%\n",
      "\n",
      "Epoch 8/20\n",
      "===============\n",
      "Loss: 0.760839\n",
      "Accuracy: 80.98%\n",
      "\n",
      "Epoch 9/20\n",
      "===============\n",
      "Loss: 0.711033\n",
      "Accuracy: 82.06%\n",
      "\n",
      "Epoch 10/20\n",
      "===============\n",
      "Loss: 0.669831\n",
      "Accuracy: 81.37%\n",
      "\n",
      "Epoch 11/20\n",
      "===============\n",
      "Loss: 0.630463\n",
      "Accuracy: 83.52%\n",
      "\n",
      "Epoch 12/20\n",
      "===============\n",
      "Loss: 0.598039\n",
      "Accuracy: 84.23%\n",
      "\n",
      "Epoch 13/20\n",
      "===============\n",
      "Loss: 0.562777\n",
      "Accuracy: 85.62%\n",
      "\n",
      "Epoch 14/20\n",
      "===============\n",
      "Loss: 0.531652\n",
      "Accuracy: 87.06%\n",
      "\n",
      "Epoch 15/20\n",
      "===============\n",
      "Loss: 0.508211\n",
      "Accuracy: 87.57%\n",
      "\n",
      "Epoch 16/20\n",
      "===============\n",
      "Loss: 0.491475\n",
      "Accuracy: 88.20%\n",
      "\n",
      "Epoch 17/20\n",
      "===============\n",
      "Loss: 0.477901\n",
      "Accuracy: 88.31%\n",
      "\n",
      "Epoch 18/20\n",
      "===============\n",
      "Loss: 0.464282\n",
      "Accuracy: 89.02%\n",
      "\n",
      "Epoch 19/20\n",
      "===============\n",
      "Loss: 0.453246\n",
      "Accuracy: 89.02%\n",
      "\n",
      "Epoch 20/20\n",
      "===============\n",
      "Loss: 0.441257\n",
      "Accuracy: 89.52%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w1_r, b1_r, w2_r, b2_r, loss_history_r = train_rmsprop(train_x, train_y, learning_rate=0.03, num_epochs=20, batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam: Moment + RMSProp\n",
    "\n",
    "Keypoints:\n",
    "\n",
    "1. Usual values of 1st moment beta is 0.9. If loss value is exploding, consding using smaller values of beta_1, __0.1 to 0.2__.\n",
    "2. Usual values of 2nd moment beta is 0.999. Similar to 1st moment, if the loss value is exploding, consider exploring smaller values of beta, __0.1 to 0.2__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adam(train_x, train_y, learning_rate=0.1, num_epochs=50, batch_size=1):\n",
    "    # Flatten input (num_samples, 28, 28) -> (num_samples, 784) \n",
    "    x = train_x.reshape(train_x.shape[0], -1)\n",
    "    num_samples = x.shape[0]\n",
    "    \n",
    "    # Turn labels into their one-hot representations\n",
    "    y = one_hot_encoder(train_y)\n",
    "\n",
    "    # Make a data loader\n",
    "    trainloader = dataloader(x, y, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Initialize weights\n",
    "    w1, b1 = initialize_weight((784, 256), bias=True)\n",
    "    w2, b2 = initialize_weight((256, 10), bias=True)\n",
    "\n",
    "    # Initialize Moments\n",
    "    s_w1, s_b1 = np.zeros(w1.shape), np.zeros(b1.shape)\n",
    "    s_w2, s_b2 = np.zeros(w2.shape), np.zeros(b2.shape)\n",
    "    v_w1, v_b1 = np.zeros(w1.shape), np.zeros(b1.shape)\n",
    "    v_w2, v_b2 = np.zeros(w2.shape), np.zeros(b2.shape)\n",
    "    \n",
    "    # Optimizer Hyperparameters\n",
    "    beta_1 = 0.9\n",
    "    beta_2 = 0.999\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    loss_history = []\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        print(\"Epoch {}/{}\\n===============\".format(epoch, num_epochs))\n",
    "\n",
    "        batch_loss = 0\n",
    "        acc = 0\n",
    "        for inputs, labels in trainloader:\n",
    "            # Number of samples per batch\n",
    "            m = inputs.shape[0]\n",
    "            \n",
    "            # Forward Prop\n",
    "            h1 = np.dot(inputs, w1) + b1\n",
    "            a1 = sigmoid(h1)\n",
    "            h2 = np.dot(a1, w2) + b2\n",
    "            a2 = softmax(h2)\n",
    "            out = a2\n",
    "\n",
    "            # Cross Entropy Loss\n",
    "            batch_loss += cross_entropy_loss(out, labels.argmax(axis=1).reshape(m,1))\n",
    "\n",
    "            # Compute Accuracy\n",
    "            pred = np.argmax(out, axis=1)\n",
    "            pred = pred.reshape(pred.shape[0], 1)\n",
    "            acc += np.sum(pred == labels.argmax(axis=1).reshape(m,1))\n",
    "\n",
    "            # Backward Prop\n",
    "            dh2 = a2 - labels \n",
    "            dw2 = (1/m) * np.dot(a1.T, dh2)\n",
    "            db2 = (1/m) * np.sum(dh2, axis=0, keepdims=True)\n",
    "\n",
    "            dh1 = np.dot(dh2, w2.T) * sigmoid_prime(a1)\n",
    "            dw1 = (1/m) * np.dot(inputs.T, dh1)\n",
    "            db1 = (1/m) * np.sum(dh1, axis=0, keepdims=True)\n",
    "\n",
    "            # 1st Moment\n",
    "            v_w2 += (beta_1 * v_w2 + (1-beta_1) * dw2) * (1-beta_1)\n",
    "            v_b2 += (beta_1 * v_b2 + (1-beta_1) * db2) * (1-beta_1)\n",
    "            v_w1 += (beta_1 * v_w1 + (1-beta_1) * dw1) * (1-beta_1)\n",
    "            v_b1 += (beta_1 * v_b1 + (1-beta_1) * db1) * (1-beta_1)\n",
    "            \n",
    "            # 2nd Moment\n",
    "            s_w2 += beta_2 * s_w2 + (1-beta_2) * dw2 * dw2\n",
    "            s_b2 += beta_2 * s_b2 + (1-beta_2) * db2 * db2\n",
    "            s_w1 += beta_2 * s_w1 + (1-beta_2) * dw1 * dw1\n",
    "            s_b1 += beta_2 * s_b1 + (1-beta_2) * db1 * db1\n",
    "            \n",
    "            # Weight (and bias) update\n",
    "            w1 -= learning_rate * v_w1 / (np.sqrt(s_w1) + epsilon)\n",
    "            b1 -= learning_rate * v_b1 / (np.sqrt(s_b1) + epsilon)\n",
    "            w2 -= learning_rate * v_w2 / (np.sqrt(s_w2) + epsilon)\n",
    "            b2 -= learning_rate * v_b2 / (np.sqrt(s_b2) + epsilon)\n",
    "            \n",
    "        loss_history.append(batch_loss/num_samples)\n",
    "        print(\"Loss: {:.6f}\".format(batch_loss/num_samples))\n",
    "        print(\"Accuracy: {:.2f}%\\n\".format(acc/num_samples*100))\n",
    "\n",
    "    return w1, b1, w2, b2, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "===============\n",
      "Loss: 2.479033\n",
      "Accuracy: 8.82%\n",
      "\n",
      "Epoch 2/20\n",
      "===============\n",
      "Loss: 2.490571\n",
      "Accuracy: 40.64%\n",
      "\n",
      "Epoch 3/20\n",
      "===============\n",
      "Loss: 1.928845\n",
      "Accuracy: 40.61%\n",
      "\n",
      "Epoch 4/20\n",
      "===============\n",
      "Loss: 1.440993\n",
      "Accuracy: 54.83%\n",
      "\n",
      "Epoch 5/20\n",
      "===============\n",
      "Loss: 1.231084\n",
      "Accuracy: 61.09%\n",
      "\n",
      "Epoch 6/20\n",
      "===============\n",
      "Loss: 1.045811\n",
      "Accuracy: 68.71%\n",
      "\n",
      "Epoch 7/20\n",
      "===============\n",
      "Loss: 0.991372\n",
      "Accuracy: 68.72%\n",
      "\n",
      "Epoch 8/20\n",
      "===============\n",
      "Loss: 0.991418\n",
      "Accuracy: 64.59%\n",
      "\n",
      "Epoch 9/20\n",
      "===============\n",
      "Loss: 0.960341\n",
      "Accuracy: 65.66%\n",
      "\n",
      "Epoch 10/20\n",
      "===============\n",
      "Loss: 0.901249\n",
      "Accuracy: 69.18%\n",
      "\n",
      "Epoch 11/20\n",
      "===============\n",
      "Loss: 0.840465\n",
      "Accuracy: 73.43%\n",
      "\n",
      "Epoch 12/20\n",
      "===============\n",
      "Loss: 0.793125\n",
      "Accuracy: 76.74%\n",
      "\n",
      "Epoch 13/20\n",
      "===============\n",
      "Loss: 0.759425\n",
      "Accuracy: 79.05%\n",
      "\n",
      "Epoch 14/20\n",
      "===============\n",
      "Loss: 0.736940\n",
      "Accuracy: 80.48%\n",
      "\n",
      "Epoch 15/20\n",
      "===============\n",
      "Loss: 0.721291\n",
      "Accuracy: 81.19%\n",
      "\n",
      "Epoch 16/20\n",
      "===============\n",
      "Loss: 0.710650\n",
      "Accuracy: 81.58%\n",
      "\n",
      "Epoch 17/20\n",
      "===============\n",
      "Loss: 0.703202\n",
      "Accuracy: 81.75%\n",
      "\n",
      "Epoch 18/20\n",
      "===============\n",
      "Loss: 0.697766\n",
      "Accuracy: 81.82%\n",
      "\n",
      "Epoch 19/20\n",
      "===============\n",
      "Loss: 0.693648\n",
      "Accuracy: 81.81%\n",
      "\n",
      "Epoch 20/20\n",
      "===============\n",
      "Loss: 0.690613\n",
      "Accuracy: 81.78%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w1_a, b1_a, w2_a, b2_a, loss_history_a = train_adam(train_x, train_y, learning_rate=0.05, num_epochs=20, batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_x, train_y, learning_rate=0.1, num_epochs=50, batch_size=1):\n",
    "    # Flatten input (num_samples, 28, 28) -> (num_samples, 784) \n",
    "    x = train_x.reshape(train_x.shape[0], -1)\n",
    "    num_samples = x.shape[0]\n",
    "    \n",
    "    # Turn labels into their one-hot representations\n",
    "    y = one_hot_encoder(train_y)\n",
    "\n",
    "    # Make a data loader\n",
    "    trainloader = dataloader(x, y, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Initialize weights\n",
    "    w1, b1 = initialize_weight((784, 256), bias=True)\n",
    "    w2, b2 = initialize_weight((256, 10), bias=True)\n",
    "\n",
    "    loss_history = []\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        print(\"Epoch {}/{}\\n===============\".format(epoch, num_epochs))\n",
    "\n",
    "        batch_loss = 0\n",
    "        acc = 0\n",
    "        for inputs, labels in trainloader:\n",
    "            # Number of samples per batch\n",
    "            m = inputs.shape[0]\n",
    "            \n",
    "            # Forward Prop\n",
    "            h1 = np.dot(inputs, w1) + b1\n",
    "            a1 = sigmoid(h1)\n",
    "            h2 = np.dot(a1, w2) + b2\n",
    "            a2 = softmax(h2)\n",
    "            out = a2\n",
    "\n",
    "            # Cross Entropy Loss\n",
    "            batch_loss += cross_entropy_loss(out, labels.argmax(axis=1).reshape(m,1))\n",
    "\n",
    "            # Compute Accuracy\n",
    "            pred = np.argmax(out, axis=1)\n",
    "            pred = pred.reshape(pred.shape[0], 1)\n",
    "            acc += np.sum(pred == labels.argmax(axis=1).reshape(m,1))\n",
    "\n",
    "            # Backward Prop\n",
    "            dh2 = a2 - labels \n",
    "            dw2 = (1/m) * np.dot(a1.T, dh2)\n",
    "            db2 = (1/m) * np.sum(dh2, axis=0, keepdims=True)\n",
    "\n",
    "            dh1 = np.dot(dh2, w2.T) * sigmoid_prime(a1)\n",
    "            dw1 = (1/m) * np.dot(inputs.T, dh1)\n",
    "            db1 = (1/m) * np.sum(dh1, axis=0, keepdims=True)\n",
    "\n",
    "            # Weight (and bias) update\n",
    "            w1 -= learning_rate * dw1\n",
    "            b1 -= learning_rate * db1\n",
    "            w2 -= learning_rate * dw2\n",
    "            b2 -= learning_rate * db2\n",
    "            \n",
    "        loss_history.append(batch_loss/num_samples)\n",
    "        print(\"Loss: {:.6f}\".format(batch_loss/num_samples))\n",
    "        print(\"Accuracy: {:.2f}%\\n\".format(acc/num_samples*100))\n",
    "\n",
    "    return w1, b1, w2, b2, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "===============\n",
      "Loss: 0.558154\n",
      "Accuracy: 84.84%\n",
      "\n",
      "Epoch 2/20\n",
      "===============\n",
      "Loss: 0.416693\n",
      "Accuracy: 88.19%\n",
      "\n",
      "Epoch 3/20\n",
      "===============\n",
      "Loss: 0.402427\n",
      "Accuracy: 88.27%\n",
      "\n",
      "Epoch 4/20\n",
      "===============\n",
      "Loss: 0.393966\n",
      "Accuracy: 88.52%\n",
      "\n",
      "Epoch 5/20\n",
      "===============\n",
      "Loss: 0.371888\n",
      "Accuracy: 89.05%\n",
      "\n",
      "Epoch 6/20\n",
      "===============\n",
      "Loss: 0.382685\n",
      "Accuracy: 88.61%\n",
      "\n",
      "Epoch 7/20\n",
      "===============\n",
      "Loss: 0.377994\n",
      "Accuracy: 88.70%\n",
      "\n",
      "Epoch 8/20\n",
      "===============\n",
      "Loss: 0.368225\n",
      "Accuracy: 88.93%\n",
      "\n",
      "Epoch 9/20\n",
      "===============\n",
      "Loss: 0.351254\n",
      "Accuracy: 89.37%\n",
      "\n",
      "Epoch 10/20\n",
      "===============\n",
      "Loss: 0.338220\n",
      "Accuracy: 89.78%\n",
      "\n",
      "Epoch 11/20\n",
      "===============\n",
      "Loss: 0.349975\n",
      "Accuracy: 89.31%\n",
      "\n",
      "Epoch 12/20\n",
      "===============\n",
      "Loss: 0.347572\n",
      "Accuracy: 89.39%\n",
      "\n",
      "Epoch 13/20\n",
      "===============\n",
      "Loss: 0.331467\n",
      "Accuracy: 89.98%\n",
      "\n",
      "Epoch 14/20\n",
      "===============\n",
      "Loss: 0.326367\n",
      "Accuracy: 89.98%\n",
      "\n",
      "Epoch 15/20\n",
      "===============\n",
      "Loss: 0.378978\n",
      "Accuracy: 88.45%\n",
      "\n",
      "Epoch 16/20\n",
      "===============\n",
      "Loss: 0.349324\n",
      "Accuracy: 89.44%\n",
      "\n",
      "Epoch 17/20\n",
      "===============\n",
      "Loss: 0.328329\n",
      "Accuracy: 90.21%\n",
      "\n",
      "Epoch 18/20\n",
      "===============\n",
      "Loss: 0.324067\n",
      "Accuracy: 90.15%\n",
      "\n",
      "Epoch 19/20\n",
      "===============\n",
      "Loss: 0.320786\n",
      "Accuracy: 90.16%\n",
      "\n",
      "Epoch 20/20\n",
      "===============\n",
      "Loss: 0.334086\n",
      "Accuracy: 89.84%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w1_mbgd, b1_mbgd, w2_mbgd, b2_mbgd, loss_history_mbgd = train(train_x, train_y, learning_rate=0.1, num_epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e983dcc1d0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Losses\n",
    "plt.plot(loss_history_m, label=\"Moment\")\n",
    "plt.plot(loss_history_r, label=\"RMSProp\")\n",
    "plt.plot(loss_history_a, label=\"Adam\")\n",
    "plt.plot(loss_history_mbgd, label=\"mini-Batch Gradient Descent\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
