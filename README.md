# Neural Network Experiments

A collection of codes and notebooks implementing various types of neural networks in Numpy. As expected, codes are not optimized, and are incapable of utilizing GPU power!

## Fundamentals of Neural Networks
1. Softmax Classification on MNIST
    * Code: [01 Softmax Regression.py](https://github.com/rrmina/Neural-Network-Experiments/blob/master/01%20Softmax%20Regression.py)
    * Notebook: [01 Softmax Regression.ipynb](https://github.com/rrmina/Neural-Network-Experiments/blob/master/01%20Softmax%20Regression.ipynb)

2. Stochastic, mini-Batch, Batch Gradient Descent, and Dataloaders
    * Code: [02 SGD, BGD, mini-BGD.py](https://github.com/rrmina/Neural-Network-Experiments/blob/master/02%20SGD,%20BGD,%20mini-BGD.py)
    * Notebook: [02 SGD, BGD, mini-BGD.ipynb](https://github.com/rrmina/Neural-Network-Experiments/blob/master/02%20SGD%2C%20BGD%2C%20mini-BGD.ipynb)

3. Optimizers (Moment, RMSProp, Adam)
    * Code: 
    * Notebook: [02 Optimizers.ipynb](https://github.com/rrmina/Neural-Network-Experiments/blob/master/03%20Optimizers.ipynb)

4. Regularization (L1, L2, Dropout, Batchnorm)
    * Code: 
    * Notebook: 

5. Convolutional Neural Networks (CNN) on MNIST
    * Code: 
    * Notebook: 

6. Recurrent Neural Networks (RNN) on MNIST
    * Code: 
    * Notebook: 

7. Generative Adversarial Networks (GANs) on MNIST
    * Code: 
    * Notebook: 

## Building Your Own Deep Learning Framework
1. Sequential Layers
    * Code:
    * Notebook:

2. Autograd
    * Code:
    * Notebook:

## Application of Neural Neworks
1. Linear and CNN Autoencoder on MNIST
    * Code: 
    * Notebook:

2. Sentiment Classification and Word Embedding on IMDB Movie Review Dataset
    * Code:
    * Notebook:

3. Character-level RNN
    * Code:
    * Notebook: